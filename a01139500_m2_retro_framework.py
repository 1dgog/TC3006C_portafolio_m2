# -*- coding: utf-8 -*-
"""a01139500_m2_retro_framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/1dgog/TC3006C_portafolio_m2/blob/main/a01139500_m2_retro_framework.ipynb

# Momento de retroalimentación con framework

## Importación de librerías y dataset
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/gdrive")
!pwd
#put your own path in google drive
# %cd "/content/gdrive/MyDrive"
!ls

"""### Librerias"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_predict

"""### Nombramiento de dataset y visualización inicial"""

columns = ["alcohol","malic_acid","ash","alcalinity_of_ash", "magnesium","total_phenols","flavanoids","nonflavanoid_phenols","proanthocyanins","color_intensity","hue","od280","proline"] # definir nombres de columna manualmente
df = pd.read_csv('wine.data',names = columns) # abrir el archivo de datos con los nombres dados para las columnas
df = df.reset_index() # se añade un nuevo indice para que el indice previo sea una clasificación que se usara en la siguiente figura.
print(df.info())
print(df.head())

"""Se nombran los datasets de entrada y salida con el que será entrenado el modelo"""

dfInput = df[["alcohol","malic_acid","ash","alcalinity_of_ash", "magnesium","total_phenols","flavanoids","nonflavanoid_phenols","proanthocyanins","color_intensity","hue","od280","proline"]]
dfOutput = df[["index"]]

"""## Aplicación de redes neuronales, scores y matrices de confusion

### Separación de datos de entrenamiento y datos de prueba
"""

X_train, X_test, y_train, y_test = train_test_split(dfInput, dfOutput, random_state=0)

"""Se hizo un ciclo for en el que se inicia con 5 capas ocultas y va hasta cuarenta con pasos de 5.

Lo mismo para el segundo que especifica el tamaño de la capa.

Estos datos se almacenan en vectores, tanto para los datos de entrenamiento como para los de test.
"""

scores_train = []
scores_test = []
almacenamiento_conf_mat_train = []
almacenamiento_conf_mat_test = []

cont = 0
for ii in range (5,40, 5):
  if cont == 1:
    scores_train.append(jj_scores_train)
    scores_test.append(jj_scores_test)
    almacenamiento_conf_mat_train.append(jj_mc_train)
    almacenamiento_conf_mat_test.append(jj_mc_test)
  cont = 1
  jj_scores_train = []
  jj_scores_test = []
  jj_mc_train = []
  jj_mc_test = []
  for jj in range(5,40,5):
    cross_val_predict,
    nnRE = MLPClassifier(hidden_layer_sizes=(ii,jj),  ## cambiar estos parámetros
                        activation='logistic', verbose=False, solver='adam',
                        learning_rate='adaptive', max_iter=2000)
    nnRE.fit(X_train,y_train)
    jj_scores_train.append(nnRE.score(X_train, y_train))
    jj_scores_test.append(nnRE.score(X_test, y_test))
    
    jj_mc_train.append(confusion_matrix(y_train,cross_val_predict(nnRE,X_train,y_train, cv = 10)))
    jj_mc_test.append(confusion_matrix(y_test,cross_val_predict(nnRE,X_test,y_test, cv = 10)))

"""Se hace presenta el cambio de los scores con respecto a los parametros ii y jj del loop, que corresponden al número de capas ocultas y su extención"""

print(np.array(scores_train))
print("--------------")
print(np.array(scores_test))
print("--------------")
np.info(np.array(scores_train))
print("--------------")
np.info(np.array(scores_test))

print(np.array(almacenamiento_conf_mat_train))
print("--------------")
print(np.array(almacenamiento_conf_mat_test))

"""### Coeficientes de las redes neuronales"""

print(nnRE)
print(nnRE.coefs_)

"""## Visualización de scores"""

cont = 0
for a in range(0,len(np.array(scores_train)),1):
  cont += 1
  plt.plot(np.array(scores_train)[a], label='%s data' % cont)
plt.legend()
plt.show()

cont = 0
for a in range(0,len(np.array(scores_test)),1):
  cont += 1
  plt.plot(np.array(scores_test)[a], label='%s data' % cont)
plt.legend()
plt.show()

"""## Visualización de cambio con respecto a matrices de confusión

Para resultados acertados
"""

sum_correcto_train = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_correcto_train.append(np.trace(np.array(almacenamiento_conf_mat_train)[ii,jj]))
sum_correcto_test = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_correcto_test.append(np.trace(np.array(almacenamiento_conf_mat_test)[ii,jj]))

cont = 0
for a in range(0,len(np.array(sum_correcto_train)),6):
  cont += 1
  plt.plot(np.array(sum_correcto_train)[a:a+7], label='%s data' % cont)
plt.legend()
plt.show()

cont = 0
for a in range(0,len(np.array(sum_correcto_test)),6):
  cont += 1
  plt.plot(np.array(sum_correcto_test)[a:a+7], label='%s data' % cont)
plt.legend()
plt.show()

"""Para resultados equivocados, se toma la resta de la suma total de los datos en la matriz, restada a los datos correctos"""

sum_incorrecto_train = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_incorrecto_train.append(np.sum(np.array(almacenamiento_conf_mat_train)[ii,jj])-np.trace(np.array(almacenamiento_conf_mat_train)[ii,jj]))
sum_incorrecto_test = []
for ii in range(0,6,1):
  for jj in range(0,6,1):
    sum_incorrecto_test.append(np.sum(np.array(almacenamiento_conf_mat_test)[ii,jj])-np.trace(np.array(almacenamiento_conf_mat_test)[ii,jj]))

cont = 0
for a in range(0,len(np.array(sum_incorrecto_train)),6):
  cont += 1
  plt.plot(np.array(sum_incorrecto_train)[a:a+7], label='%s data' % cont)
plt.legend()
plt.show()

cont = 0
for a in range(0,len(np.array(sum_incorrecto_test)),6):
  cont += 1
  plt.plot(np.array(sum_incorrecto_test)[a:a+7], label='%s data' % cont)
plt.legend()
plt.show()

"""## Notas de asesoría.

Sesgo y varianza, estan relacionados, tiene que ver con el overfitting. Si tiene poco ses

Poner en terminos de bajo, medio y alto. 

No es necesario que sea de varios frameworks, con uno basta.}

Se pueden hacer gráficas de como cambia el score.
"""